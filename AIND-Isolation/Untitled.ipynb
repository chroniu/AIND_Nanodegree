{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class SearchTimeout(Exception):\n",
    "    \"\"\"Subclass base exception for code clarity. \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    This should be the best heuristic function for your project submission.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    # TODO: finish this function!\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def custom_score_2(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    # TODO: finish this function!\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def custom_score_3(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    # TODO: finish this function!\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class IsolationPlayer:\n",
    "    \"\"\"Base class for minimax and alphabeta agents -- this class is never\n",
    "    constructed or tested directly.\n",
    "\n",
    "    ********************  DO NOT MODIFY THIS CLASS  ********************\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_depth : int (optional)\n",
    "        A strictly positive integer (i.e., 1, 2, 3,...) for the number of\n",
    "        layers in the game tree to explore for fixed-depth search. (i.e., a\n",
    "        depth of one (1) would only explore the immediate sucessors of the\n",
    "        current state.)\n",
    "\n",
    "    score_fn : callable (optional)\n",
    "        A function to use for heuristic evaluation of game states.\n",
    "\n",
    "    timeout : float (optional)\n",
    "        Time remaining (in milliseconds) when search is aborted. Should be a\n",
    "        positive value large enough to allow the function to return before the\n",
    "        timer expires.\n",
    "    \"\"\"\n",
    "    def __init__(self, search_depth=3, score_fn=custom_score, timeout=10.):\n",
    "        self.search_depth = search_depth\n",
    "        self.score = score_fn\n",
    "        self.time_left = None\n",
    "        self.TIMER_THRESHOLD = timeout\n",
    "\n",
    "\n",
    "class MinimaxPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using depth-limited minimax\n",
    "    search. You must finish and test this player to make sure it properly uses\n",
    "    minimax to return a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        **************  YOU DO NOT NEED TO MODIFY THIS FUNCTION  *************\n",
    "\n",
    "        For fixed-depth search, this function simply wraps the call to the\n",
    "        minimax method, but this method provides a common interface for all\n",
    "        Isolation agents, and you will replace it in the AlphaBetaPlayer with\n",
    "        iterative deepening search.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "\n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            return self.minimax(game, self.search_depth)\n",
    "\n",
    "        except SearchTimeout:\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        return best_move\n",
    "    \n",
    "    def minimax(self, game, depth):\n",
    "        \"\"\"Implement depth-limited minimax search algorithm as described in\n",
    "        the lectures.\n",
    "\n",
    "        This should be a modified version of MINIMAX-DECISION in the AIMA text.\n",
    "        https://github.com/aimacode/aima-pseudocode/blob/master/md/Minimax-Decision.md\n",
    "\n",
    "        **********************************************************************\n",
    "            You MAY add additional methods to this class, or define helper\n",
    "                 functions to implement the required functionality.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            The board coordinates of the best move found in the current search;\n",
    "            (-1, -1) if there are no legal moves\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project tests; you cannot call any other evaluation\n",
    "                function directly.\n",
    "\n",
    "            (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "                pseudocode) then you must copy the timer check into the top of\n",
    "                each helper function or else your agent will timeout during\n",
    "                testing.\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "        best_score = float(\"-inf\")\n",
    "        best_move = None\n",
    "        print(\"type of game\", type(game))\n",
    "        for m in game.get_legal_moves():\n",
    "            \n",
    "        # call has been updated with a depth limit\n",
    "            v = self.min_value(game.forecast_move(m), depth - 1)\n",
    "            if v > best_score:\n",
    "                best_score = v\n",
    "                best_move = m\n",
    "        return best_move\n",
    "\n",
    "\n",
    "    def min_value(self, gameState, depth):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \"\"\" Return the value for a win (+1) if the game is over,\n",
    "        otherwise return the minimum value over all legal child\n",
    "        nodes.\n",
    "        \"\"\"\n",
    "        if terminal_test(gameState):\n",
    "            return 1  # by Assumption 2\n",
    "        if depth == 0:\n",
    "            return -1\n",
    "        \n",
    "        v = float(\"inf\")\n",
    "        for m in gameState.get_legal_moves():\n",
    "            v = min(v, self.max_value(gameState.forecast_move(m), depth -1))\n",
    "        return v\n",
    "\n",
    "\n",
    "    def max_value(self, gameState, depth):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \"\"\" Return the value for a loss (-1) if the game is over,\n",
    "        otherwise return the maximum value over all legal child\n",
    "        nodes.\n",
    "        \"\"\"\n",
    "        if terminal_test(gameState):\n",
    "            return -1  # by assumption 2\n",
    "        if depth == 0:\n",
    "            return 1\n",
    "\n",
    "        v = float(\"-inf\")\n",
    "        for m in gameState.get_legal_moves():\n",
    "            v = max(v, self.min_value(gameState.forecast_move(m), depth -1))\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of game <class 'isolation.isolation.Board'>\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba1e03517d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinimaxPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mget_move\u001b[0;34m(self, game, time_left)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# The try/except block will automatically catch the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;31m# raised when the timer is about to expire.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSearchTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mminimax\u001b[0;34m(self, game, depth)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# call has been updated with a depth limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, gameState, depth)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mmax_value\u001b[0;34m(self, gameState, depth)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mmin_value\u001b[0;34m(self, gameState, depth)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;31m#            return 1  # by Assumption 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgameState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-nanodegree/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mcustom_score\u001b[0;34m(game, player)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# TODO: finish this function!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def time_left():\n",
    "    return 10\n",
    "\n",
    "\n",
    "import unittest\n",
    "import game_agent\n",
    "import isolation\n",
    "\n",
    "\n",
    "player1 = \"Player1\"\n",
    "player2 = \"Player2\"\n",
    "game = isolation.Board(player1, player2)\n",
    "\n",
    "player = game_agent.IsolationPlayer()\n",
    "g = game_agent.MinimaxPlayer()\n",
    "\n",
    "g.get_move(game, time_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
